import asyncio
import os
import sys
import time
from pathlib import Path
from typing import Dict, List

# Ajustar el path para importar los m√≥dulos hermanos si es necesario
sys.path.append(str(Path(__file__).parent))

from async_pdf_processor import PDFProcessor
from rag_core import RagEngine

# --- Configuraci√≥n de Rutas (Igual que en benchmark.py) ---
BASE_DIR = Path(__file__).parent.parent 
MODEL_PATH = BASE_DIR / "data" / "models" / "all-MiniLM-L6-v2"
RERANK_PATH = BASE_DIR / "data" / "models" / "ms-marco-TinyBERT-L-2-v2"
# Usamos una DB espec√≠fica para la demo para no mezclar con pruebas
DB_PATH = BASE_DIR / "data" / "databases" / "chroma_demo"

def clear_screen():
    os.system('cls' if os.name == 'nt' else 'clear')

def print_header():
    print("=" * 60)
    print("ü§ñ  RAG PROTOTYPE DEMO - CONFIDENTIAL AI")
    print("    Stack: ONNX (CPU) + ChromaDB + Hybrid Search")
    print("=" * 60 + "\n")

async def process_documents(folder_path: str) -> Dict[str, str]:
    """
    Usa el procesador as√≠ncrono para leer los PDFs.
    Retorna un diccionario {nombre_archivo: texto_completo}.
    """
    processor = PDFProcessor(max_chunk_size=1000, chunk_overlap=100, logs_level=40) # 40 = ERROR para reducir ruido
    file_contents: Dict[str, List[str]] = {}
    
    print(f"üìÇ  Leyendo archivos desde: {folder_path}")
    print("‚è≥  Procesando PDFs (Extracci√≥n de texto y tablas)...")
    
    start_time = time.time()
    count = 0
    
    # Procesamiento as√≠ncrono
    try:
        async for filepath, page_num, chunk in processor.process_pdfs(folder_path, detect_tables=True):
            filename = Path(filepath).name
            if filename not in file_contents:
                file_contents[filename] = []
                print(f"   üìÑ Detectado: {filename}")
            
            file_contents[filename].append(chunk)
            count += 1
            # Simple indicador de progreso
            print(f"      ‚Ü≥ Extrayendo: {filename} (P√°g {page_num})", end="\r")
            
    except Exception as e:
        print(f"\n‚ùå  Error procesando PDFs: {e}")
        return {}

    print(f"\n‚úÖ  Procesamiento finalizado: {count} fragmentos extra√≠dos en {time.time() - start_time:.2f}s.\n")
    
    # Unir fragmentos para entregar documentos "enteros" al RagEngine
    # Esto permite que el RagEngine aplique su propia l√≥gica de Parent-Child splitting
    documents = {name: "\n".join(chunks) for name, chunks in file_contents.items()}
    return documents

def run_rag_demo():
    clear_screen()
    print_header()

    # 1. Verificaci√≥n de Modelos
    if not MODEL_PATH.exists() or not RERANK_PATH.exists():
        print("‚ùå  Error: Modelos no encontrados.")
        print("    Por favor ejecuta primero: python src/setup_models.py")
        return

    # 2. Carga del Motor (Cold Start)
    print("‚öôÔ∏è   Cargando Modelos ONNX y Base de Datos Vectorial...")
    start_load = time.time()
    engine = RagEngine(str(MODEL_PATH), str(RERANK_PATH), str(DB_PATH))
    print(f"‚úÖ  Motor listo en {time.time() - start_load:.2f}s.\n")

    # 3. Selecci√≥n de Carpeta
    while True:
        folder_input = input("ptr  Introduce la ruta de la carpeta con PDFs (o 'enter' para usar ./docs): ").strip()
        if not folder_input:
            target_folder = BASE_DIR / "docs"
        else:
            target_folder = Path(folder_input)
        
        if target_folder.exists() and target_folder.is_dir():
            break
        print("‚ùå  Ruta inv√°lida. Intenta de nuevo.")

    # 4. Procesamiento e Ingesta
    # Ejecutamos la parte as√≠ncrona
    raw_documents = asyncio.run(process_documents(str(target_folder)))
    
    if not raw_documents:
        print("‚ö†Ô∏è  No se encontraron documentos v√°lidos o texto extra√≠ble.")
    else:
        print("üß†  Ingestando en RAG (Embedding + Indexado + BM25)...")
        total_chunks = 0
        for filename, content in raw_documents.items():
            print(f"   ‚Ü≥ Indexando: {filename}...", end="")
            # Ingesta en el motor
            n_chunks = engine.ingest(content, project_id="demo_v1")
            total_chunks += n_chunks
            print(f" Hecho ({n_chunks} sub-chunks creados)")
        print(f"‚úÖ  Base de conocimiento actualizada. Total vectores: {total_chunks}\n")

    # 5. Bucle de Preguntas
    print("=" * 60)
    print("üí¨  SISTEMA LISTO. Escribe 'salir' para terminar.")
    print("=" * 60)

    while True:
        query = input("\nPregunta ‚û§ ")
        if query.lower() in ['salir', 'exit', 'quit']:
            break
        
        if not query.strip():
            continue

        print("üîç  Buscando y Re-rankeando informaci√≥n relevante...")
        start_q = time.time()
        
        # B√∫squeda
        try:
            # engine.search devuelve un string con los contextos unidos
            context_chunks = engine.search(query, top_k=3)
            
            elapsed = time.time() - start_q
            
            print(f"\n--- üìÑ Contexto Recuperado (Tiempo: {elapsed:.3f}s) ---")
            if not context_chunks:
                print("‚ö†Ô∏è  No se encontr√≥ informaci√≥n relevante en los documentos.")
            else:
                # Mostramos el contexto recuperado
                print("Fragmentos relevantes:  \n")
                for chunk in context_chunks:
                    print("-" * 60)
                    print(chunk)
            print("-" * 60)
            
        except Exception as e:
            print(f"‚ùå  Error durante la b√∫squeda: {e}")

if __name__ == "__main__":
    try:
        run_rag_demo()
    except KeyboardInterrupt:
        print("\n\nüëã Demo finalizada por el usuario.")